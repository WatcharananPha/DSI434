{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351d9bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\kongl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "C:\\Users\\kongl\\AppData\\Local\\Temp\\ipykernel_17604\\3277173220.py:199: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  return pd.date_range(t0, t1, freq=f\"{dt_hours}H\", tz=\"UTC\")\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOverflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 358\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_render_llm_prompt\u001b[39m(ctx: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mคุณคือ Data/Quant strategist ภาษาไทย ทำหน้าที่แปลผลลัพธ์เชิงตัวเลขจาก BSDE framework ให้กลายเป็นนโยบายที่ปฏิบัติได้จริง \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mให้ตอบเป็นภาษาไทยแบบ dev/data expert ทับศัพท์และคงชื่อเทคนิค เช่น BSDE, intensity, severity, utility\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mห้ามตอบเป็นโค้ดหรือครอบด้วย code fence\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    356\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m \u001b[43mrun_bsde_pipeline_and_report\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10_000_000.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 280\u001b[39m, in \u001b[36mrun_bsde_pipeline_and_report\u001b[39m\u001b[34m(budget_total_thb)\u001b[39m\n\u001b[32m    278\u001b[39m F = fit_severity_lognormal(claims_df[\u001b[33m\"\u001b[39m\u001b[33mz\u001b[39m\u001b[33m\"\u001b[39m].values)\n\u001b[32m    279\u001b[39m baseline = simulate_value(lam0, F, \u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m, CFG)\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m best = \u001b[43mgrid_search_controls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlam0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m report = {\n\u001b[32m    282\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m: {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m CFG.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mseverity_proxy\u001b[39m\u001b[33m\"\u001b[39m,)},\n\u001b[32m    283\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtime_grid_start\u001b[39m\u001b[33m\"\u001b[39m: grid[\u001b[32m0\u001b[39m].isoformat() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(grid) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    290\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimprovement_ratio\u001b[39m\u001b[33m\"\u001b[39m: (baseline / best[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m best[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    291\u001b[39m }\n\u001b[32m    292\u001b[39m (OUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mpolicy.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(json.dumps(report, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 265\u001b[39m, in \u001b[36mgrid_search_controls\u001b[39m\u001b[34m(lambda_series, F, cfg)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u1 \u001b[38;5;129;01min\u001b[39;00m grid:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m u2 \u001b[38;5;129;01min\u001b[39;00m grid:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m         val = \u001b[43msimulate_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m val < best[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    267\u001b[39m             best = {\u001b[33m\"\u001b[39m\u001b[33mu1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(u1), \u001b[33m\"\u001b[39m\u001b[33mu2\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(u2), \u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(val)}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 257\u001b[39m, in \u001b[36msimulate_value\u001b[39m\u001b[34m(lambda_series, F, u1, u2, cfg)\u001b[39m\n\u001b[32m    255\u001b[39m             X -= loss\n\u001b[32m    256\u001b[39m         X -= cdt * dt\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     vals[p] = \u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43meta\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.mean(vals))\n",
      "\u001b[31mOverflowError\u001b[39m: math range error"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from google import genai\n",
    "\n",
    "EXCEL_PATH = Path(\"BIA_clean.xlsx\")\n",
    "BASE_DIR = Path(\"bia_txt\")\n",
    "RAW_DIR = BASE_DIR / \"raw\"\n",
    "PREP_DIR = BASE_DIR / \"prepared\"\n",
    "OUT_DIR = Path(\"bsde_out\")\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "API_KEY = \"AIzaSyAndvZufK3ms-pYx8DO7vBGJjaxsfS-Ecs\"\n",
    "CHUNK_SIZE = 8192\n",
    "\n",
    "CFG = {\n",
    "    \"timezone\": \"Asia/Bangkok\",\n",
    "    \"dt_hours\": 1,\n",
    "    \"r\": 0.03,\n",
    "    \"eta\": 0.5,\n",
    "    \"x0\": 0.0,\n",
    "    \"k1\": 1.2,\n",
    "    \"k2\": 1.0,\n",
    "    \"c1_a\": 0.0,\n",
    "    \"c1_b\": 2.0e5,\n",
    "    \"c2_a\": 0.0,\n",
    "    \"c2_b\": 1.0e5,\n",
    "    \"n_paths\": 4000,\n",
    "    \"u_grid\": 11,\n",
    "    \"severity_proxy\": {2: 2_000_000.0, 3: 500_000.0}\n",
    "}\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PREP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_name(name: str) -> str:\n",
    "    return \"\".join(c if c.isalnum() or c in \"-_. \" else \"_\" for c in str(name)).strip().replace(\" \", \"_\")\n",
    "\n",
    "def excel_to_tsvs(xlsx: Path, out_dir: Path):\n",
    "    sheets = pd.read_excel(xlsx, sheet_name=None, dtype=str, engine=\"openpyxl\")\n",
    "    fps = []\n",
    "    for sheet, df in sheets.items():\n",
    "        df = df.fillna(\"\")\n",
    "        fp = out_dir / f\"{_safe_name(sheet)}.raw.txt\"\n",
    "        df.to_csv(fp, sep=\"\\t\", index=False, lineterminator=\"\\n\")\n",
    "        fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "def _manual_events_df():\n",
    "    rows = [\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"9-Mar-20\",\"รายละเอียด\":\"ABCT breaker 5YB-01 trip by relay 87L operate\",\"ระดับความรุนแรง\":\"2\",\"ความสำคัญในการประเมิน BIA\":\"สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"24-May-20\",\"รายละเอียด\":\"Plant islanding due to ban chang substation switching line to bay spare (inter trip not support this function)\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"22-Jun-20\",\"รายละเอียด\":\"GTG-11 trip by 1391VA979HH and PEA 1YB-01 OPEN plant Islanding by relay 21/21N Zone1\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"27-Jun-20\",\"รายละเอียด\":\"GTG-14 was tripped by Load GEAR#1&2 AXIS VIBRAT.high\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"13-Aug-20\",\"รายละเอียด\":\"GTG-11 was tripped by alarm TAHH 534-541 Brg.Metal Temp high trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"1-Sep-20\",\"รายละเอียด\":\"GTG11 was tripped by Generator Vibration high trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"26-Nov-20\",\"รายละเอียด\":\"Close 52Aux (GTG-12) 87T operate 52L1 Open,52G Open and GTG-12 trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"25-Feb-21\",\"รายละเอียด\":\"Aux Boiler trip by burner inlet fuel gas pressure low low\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"19-Feb-21 16:00\",\"รายละเอียด\":\"Plant islanding, 1YB01 open by inter trip 5YB01 operate from Banchang substation\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"13-Apr-21 02:39\",\"รายละเอียด\":\"PEA Maptaphut3 substation tripped. This event impacted to customers (MIGP ,ABCT, LLDPE2) tripped.\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"14-Apr-21 11:15\",\"รายละเอียด\":\"GTG11&HRSG11 and GTG12&HRSG12 tripped.\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"14-Apr-21 11:28\",\"รายละเอียด\":\"GTG15&HRSG15 tripped.\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"20-Apr-21 14:33\",\"รายละเอียด\":\"CUP1 plant blackout.\",\"ระดับความรุนแรง\":\"2\",\"ความสำคัญในการประเมิน BIA\":\"สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"29-Apr-21 18:24\",\"รายละเอียด\":\"GTG12 tripped.\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"6-May-21 23:55\",\"รายละเอียด\":\"GTG16 tripped.\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"10-May-21 11:44\",\"รายละเอียด\":\"Plant islanding by external fault.(distance relay operated)  12:17 Synchronize to PEA.\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"16-May-21 23:55\",\"รายละเอียด\":\"GTG13 GEN Breaker 52G opened by lost of power 400 V supply to ACC. Motors\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"28-May-21 04:27\",\"รายละเอียด\":\"Plant islanding from external fault (distance relay Z1 operated) impact to customers some load trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"9-Jul-21 10:29\",\"รายละเอียด\":\"GTG11 was tripped by alarm seismic vibration GEN HH trip (39VT) & GTG16 was trip by alarm 77HT module speed signal loss\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"15-Jul-21 01:05\",\"รายละเอียด\":\"GTG11 was tripped by alarm seismic vibration GEN HH trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"19-Aug-21 01:05\",\"รายละเอียด\":\"GTG11 was tripped by alarm vibration 1391VAHH729X HH trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"22-Sep-21 04:45\",\"รายละเอียด\":\"Aux Boiler trip by burner inlet fuel gas pressure low low\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"21-Oct-21 17:01\",\"รายละเอียด\":\"GTG11 was tripped by alarm vibration 1391VAHH729X HH trip\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"9-Nov-21 17:01\",\"รายละเอียด\":\"GTG15 was tripped by alarm VPRO Diagnostic\",\"ระดับความรุนแรง\":\"3\",\"ความสำคัญในการประเมิน BIA\":\"ไม่สำคัญ\"},\n",
    "        {\"วันเดือนปีที่เกิดเหตุ\":\"27-Nov-21 11:42\",\"รายละเอียด\":\"PTTAC 115 kV CB 7YB-01 opened to PTTAC was tripped by alarm reverse power relay\",\"ระดับความรุนแรง\":\"2\",\"ความสำคัญในการประเมิน BIA\":\"สำคัญ\"},\n",
    "    ]\n",
    "    return pd.DataFrame(rows, columns=[\"วันเดือนปีที่เกิดเหตุ\",\"รายละเอียด\",\"ระดับความรุนแรง\",\"ความสำคัญในการประเมิน BIA\"]).fillna(\"\")\n",
    "\n",
    "def write_manual_raw(out_dir: Path):\n",
    "    df = _manual_events_df()\n",
    "    fp = out_dir / \"Manual_Events.raw.txt\"\n",
    "    df.to_csv(fp, sep=\"\\t\", index=False, lineterminator=\"\\n\")\n",
    "    return fp\n",
    "\n",
    "def _tsv_chunks(text: str, size: int):\n",
    "    lines = text.splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    header = lines[0]\n",
    "    cur = [header]\n",
    "    total = len(header)\n",
    "    for r in lines[1:]:\n",
    "        ln = len(r) + 1\n",
    "        if total + ln > size and len(cur) > 1:\n",
    "            yield \"\\n\".join(cur)\n",
    "            cur = [header]\n",
    "            total = len(header)\n",
    "        cur.append(r)\n",
    "        total += ln\n",
    "    if len(cur) > 1:\n",
    "        yield \"\\n\".join(cur)\n",
    "\n",
    "def _prep_prompt(sheet_name: str, tsv_chunk: str) -> str:\n",
    "    return (\n",
    "        \"Convert TSV to JSON Lines. One JSON object per line with fields: sheet:string, row_index:int (1-based inside chunk), \"\n",
    "        \"data:object with snake_case keys. Trim leading/trailing spaces, collapse internal newlines to a single space, drop rows with all-empty columns, \"\n",
    "        \"preserve dates as-is when uncertain, output JSON Lines only (no markdown, no commentary). \"\n",
    "        f\"sheet={sheet_name}\\nTSV:\\n{tsv_chunk}\"\n",
    "    )\n",
    "\n",
    "def _strip_fence(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"```\"):\n",
    "        parts = s.split(\"```\")\n",
    "        if len(parts) >= 3:\n",
    "            return parts[1].strip()\n",
    "        return s.replace(\"```\", \"\").strip()\n",
    "    return s\n",
    "\n",
    "def transform_raw_with_gemini(raw_path: Path, out_dir: Path, client: genai.Client, chunk_size: int = CHUNK_SIZE):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    src = raw_path.stem.replace(\".raw\", \"\")\n",
    "    text = raw_path.read_text(encoding=\"utf-8-sig\")\n",
    "    parts = []\n",
    "    for chunk in _tsv_chunks(text, chunk_size):\n",
    "        prompt = _prep_prompt(src, chunk)\n",
    "        resp = client.models.generate_content(model=MODEL, contents=prompt)\n",
    "        parts.append(_strip_fence(getattr(resp, \"text\", str(resp))))\n",
    "    prepared_fp = out_dir / f\"{src}.prepared.txt\"\n",
    "    prepared_text = \"\\n\".join([p for p in parts if p]).strip()\n",
    "    prepared_fp.write_text(prepared_text + (\"\\n\" if prepared_text else \"\"), encoding=\"utf-8\")\n",
    "    return prepared_fp\n",
    "\n",
    "def convert_bia_to_raw_and_prepare():\n",
    "    fps = []\n",
    "    if EXCEL_PATH.exists():\n",
    "        fps += excel_to_tsvs(EXCEL_PATH, RAW_DIR)\n",
    "    fps.append(write_manual_raw(RAW_DIR))\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    prepared = []\n",
    "    for rp in sorted(RAW_DIR.glob(\"*.raw.txt\")):\n",
    "        prepared.append(transform_raw_with_gemini(rp, PREP_DIR, client, CHUNK_SIZE))\n",
    "    return prepared\n",
    "\n",
    "def _read_json_lines(path: Path):\n",
    "    for line in path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"{\") and line.endswith(\"}\"):\n",
    "            j = json.loads(line)\n",
    "            yield j\n",
    "\n",
    "def _coerce_claim(obj: dict):\n",
    "    if \"type\" in obj and obj[\"type\"] == \"claim\":\n",
    "        return {\"t\": obj.get(\"t\"), \"desc\": obj.get(\"desc\"), \"severity_level\": obj.get(\"severity_level\"), \"bia_importance\": obj.get(\"bia_importance\"), \"z\": obj.get(\"z\"), \"z_proxy_thb\": obj.get(\"z_proxy_thb\")}\n",
    "    if \"data\" in obj:\n",
    "        d = obj[\"data\"]\n",
    "        t = d.get(\"วันเดือนปีที่เกิดเหตุ\") or d.get(\"date\") or d.get(\"t\")\n",
    "        desc = d.get(\"รายละเอียด\") or d.get(\"desc\") or d.get(\"event\")\n",
    "        sev = d.get(\"ระดับความรุนแรง\") or d.get(\"severity\") or d.get(\"severity_level\")\n",
    "        bia = d.get(\"ความสำคัญในการประเมิน_bia\") or d.get(\"ความสำคัญในการประเมิน bia\") or d.get(\"bia_importance\")\n",
    "        z = d.get(\"z\") or d.get(\"loss\") or None\n",
    "        zpx = d.get(\"z_proxy_thb\") or None\n",
    "        return {\"t\": t, \"desc\": desc, \"severity_level\": sev, \"bia_importance\": bia, \"z\": z, \"z_proxy_thb\": zpx}\n",
    "    return None\n",
    "\n",
    "def load_claims_df(prep_dir: Path, severity_proxy: dict, tz: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fp in sorted(prep_dir.glob(\"*.prepared.txt\")):\n",
    "        for obj in _read_json_lines(fp):\n",
    "            r = _coerce_claim(obj)\n",
    "            if r:\n",
    "                rows.append(r)\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    s = df.get(\"bia_importance\").astype(str).str.strip()\n",
    "    df[\"bia_importance\"] = np.where(s.str.contains(\"สำคัญ\"), \"critical\", \"non_critical\")\n",
    "    df[\"severity_level\"] = pd.to_numeric(df.get(\"severity_level\"), errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"z\"] = pd.to_numeric(df.get(\"z\"), errors=\"coerce\")\n",
    "    df[\"z_proxy_thb\"] = pd.to_numeric(df.get(\"z_proxy_thb\"), errors=\"coerce\")\n",
    "    m = df[\"z\"].isna()\n",
    "    df.loc[m & df[\"severity_level\"].notna(), \"z\"] = df.loc[m & df[\"severity_level\"].notna(), \"severity_level\"].map(severity_proxy)\n",
    "    df.loc[m & df[\"z_proxy_thb\"].notna(), \"z\"] = df.loc[m & df[\"z_proxy_thb\"].notna(), \"z_proxy_thb\"]\n",
    "    df[\"t\"] = pd.to_datetime(df.get(\"t\"), errors=\"coerce\", utc=True)\n",
    "    df = df.dropna(subset=[\"t\",\"z\"]).sort_values(\"t\").reset_index(drop=True)\n",
    "    return df[[\"t\",\"z\",\"severity_level\",\"bia_importance\"]]\n",
    "\n",
    "def build_time_grid(df: pd.DataFrame, dt_hours: int):\n",
    "    t_series = pd.to_datetime(df[\"t\"], errors=\"coerce\", utc=True).dropna()\n",
    "    if t_series.empty:\n",
    "        return pd.DatetimeIndex([], tz=\"UTC\")\n",
    "    t0 = pd.Timestamp(t_series.min()).floor(f\"{dt_hours}h\")\n",
    "    t1 = pd.Timestamp(t_series.max()).ceil(f\"{dt_hours}h\")\n",
    "    return pd.date_range(t0, t1, freq=f\"{dt_hours}H\", tz=\"UTC\")\n",
    "\n",
    "def estimate_lambda0(df: pd.DataFrame, grid: pd.DatetimeIndex, dt_hours: int) -> np.ndarray:\n",
    "    if len(grid) < 2:\n",
    "        return np.array([], dtype=float)\n",
    "    cuts = pd.cut(df[\"t\"], bins=grid, right=False, include_lowest=True)\n",
    "    counts = df.groupby(cuts, observed=False).size().reindex(pd.IntervalIndex.from_breaks(grid), fill_value=0).values\n",
    "    lam = counts.astype(float) / float(dt_hours)\n",
    "    return lam\n",
    "\n",
    "def fit_severity_lognormal(z: np.ndarray):\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    z = z[z > 0]\n",
    "    logz = np.log(z)\n",
    "    mu = float(np.mean(logz))\n",
    "    sigma = float(np.std(logz, ddof=1)) if len(logz) > 1 else 1e-6\n",
    "    def sample(n):\n",
    "        return np.exp(np.random.normal(mu, sigma, size=n))\n",
    "    def moment(func, n_mc=20000):\n",
    "        x = sample(n_mc)\n",
    "        return float(np.mean(func(x)))\n",
    "    return {\"mu\": mu, \"sigma\": sigma, \"sample\": sample, \"moment\": moment}\n",
    "\n",
    "def gamma1(u1: float, k1: float):\n",
    "    return math.exp(-k1 * max(0.0, min(1.0, u1)))\n",
    "\n",
    "def gamma2(u2: float, k2: float):\n",
    "    return math.exp(-k2 * max(0.0, min(1.0, u2)))\n",
    "\n",
    "def cost1(u1: float, a: float, b: float):\n",
    "    u1 = max(0.0, min(1.0, u1))\n",
    "    return a * u1 + 0.5 * b * u1 * u1\n",
    "\n",
    "def cost2(u2: float, a: float, b: float):\n",
    "    u2 = max(0.0, min(1.0, u2))\n",
    "    return a * u2 + 0.5 * b * u2 * u2\n",
    "\n",
    "def simulate_value(lambda_series: np.ndarray, F, u1: float, u2: float, cfg: dict):\n",
    "    dt = cfg[\"dt_hours\"]\n",
    "    r = cfg[\"r\"]\n",
    "    eta = cfg[\"eta\"]\n",
    "    x = cfg[\"x0\"]\n",
    "    g1 = gamma1(u1, cfg[\"k1\"])\n",
    "    g2 = gamma2(u2, cfg[\"k2\"])\n",
    "    cdt = cost1(u1, cfg[\"c1_a\"], cfg[\"c1_b\"]) + cost2(u2, cfg[\"c2_a\"], cfg[\"c2_b\"])\n",
    "    n_paths = cfg[\"n_paths\"]\n",
    "    lam_u = g1 * lambda_series\n",
    "    T_steps = len(lambda_series)\n",
    "    vals = np.empty(n_paths, dtype=float)\n",
    "    for p in range(n_paths):\n",
    "        X = x\n",
    "        for k in range(T_steps):\n",
    "            X += r * X * dt\n",
    "            N = np.random.poisson(max(0.0, lam_u[k]) * dt)\n",
    "            if N > 0:\n",
    "                loss = float(np.sum(g2 * F[\"sample\"](N)))\n",
    "                X -= loss\n",
    "            X -= cdt * dt\n",
    "        vals[p] = math.exp(-eta * X)\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "def grid_search_controls(lambda_series: np.ndarray, F, cfg: dict):\n",
    "    grid = np.linspace(0.0, 1.0, cfg[\"u_grid\"])\n",
    "    best = {\"u1\": 0.0, \"u2\": 0.0, \"objective\": float(\"inf\")}\n",
    "    for u1 in grid:\n",
    "        for u2 in grid:\n",
    "            val = simulate_value(lambda_series, F, u1, u2, cfg)\n",
    "            if val < best[\"objective\"]:\n",
    "                best = {\"u1\": float(u1), \"u2\": float(u2), \"objective\": float(val)}\n",
    "    return best\n",
    "\n",
    "def run_bsde_pipeline_and_report(budget_total_thb: float = 10_000_000.0):\n",
    "    convert_bia_to_raw_and_prepare()\n",
    "    claims_df = load_claims_df(PREP_DIR, CFG[\"severity_proxy\"], CFG[\"timezone\"])\n",
    "    if claims_df.empty:\n",
    "        (OUT_DIR / \"status.txt\").write_text(\"no_claims_rows\", encoding=\"utf-8\")\n",
    "        return\n",
    "    grid = build_time_grid(claims_df, CFG[\"dt_hours\"])\n",
    "    lam0 = estimate_lambda0(claims_df, grid, CFG[\"dt_hours\"])\n",
    "    F = fit_severity_lognormal(claims_df[\"z\"].values)\n",
    "    baseline = simulate_value(lam0, F, 0.0, 0.0, CFG)\n",
    "    best = grid_search_controls(lam0, F, CFG)\n",
    "    report = {\n",
    "        \"config\": {k: v for k, v in CFG.items() if k not in (\"severity_proxy\",)},\n",
    "        \"time_grid_start\": grid[0].isoformat() if len(grid) else None,\n",
    "        \"time_grid_end\": grid[-1].isoformat() if len(grid) else None,\n",
    "        \"steps\": int(len(lam0)),\n",
    "        \"lambda0_avg_per_dt\": float(np.mean(lam0)) if len(lam0) else 0.0,\n",
    "        \"severity_lognormal\": {\"mu\": F[\"mu\"], \"sigma\": F[\"sigma\"]},\n",
    "        \"baseline_E_exp_minus_eta_XT\": baseline,\n",
    "        \"optimal\": best,\n",
    "        \"improvement_ratio\": (baseline / best[\"objective\"]) if best[\"objective\"] > 0 else None\n",
    "    }\n",
    "    (OUT_DIR / \"policy.json\").write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    series = pd.DataFrame({\n",
    "        \"t_bin_start_utc\": grid[:-1].astype(\"datetime64[ns]\") if len(grid) > 1 else pd.to_datetime([]),\n",
    "        \"lambda0_per_hour\": lam0 if len(lam0) else np.array([]),\n",
    "    })\n",
    "    series.to_csv(OUT_DIR / \"lambda_series.csv\", index=False, encoding=\"utf-8\")\n",
    "    ctx = {\n",
    "        \"baseline\": report.get(\"baseline_E_exp_minus_eta_XT\"),\n",
    "        \"optimal_objective\": report.get(\"optimal\", {}).get(\"objective\"),\n",
    "        \"improvement_ratio\": report.get(\"improvement_ratio\"),\n",
    "        \"steps\": report.get(\"steps\"),\n",
    "        \"avg_lambda\": report.get(\"lambda0_avg_per_dt\"),\n",
    "        \"u1\": report.get(\"optimal\", {}).get(\"u1\"),\n",
    "        \"u2\": report.get(\"optimal\", {}).get(\"u2\"),\n",
    "        \"r\": report.get(\"config\", {}).get(\"r\"),\n",
    "        \"eta\": report.get(\"config\", {}).get(\"eta\"),\n",
    "        \"budget\": float(budget_total_thb),\n",
    "        \"lambda_table\": _compact_table(series.head(24))\n",
    "    }\n",
    "    prompt = _render_llm_prompt(ctx)\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    resp = client.models.generate_content(model=MODEL, contents=prompt)\n",
    "    text = getattr(resp, \"text\", str(resp)).strip()\n",
    "    (OUT_DIR / \"llm_report.md\").write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "def _compact_table(df: pd.DataFrame, max_rows: int = 50):\n",
    "    if df.empty:\n",
    "        return \"\"\n",
    "    df = df.copy().iloc[:max_rows]\n",
    "    cols = df.columns.astype(str).tolist()\n",
    "    lines = []\n",
    "    lines.append(\"|\" + \"|\".join(cols) + \"|\")\n",
    "    lines.append(\"|\" + \"|\".join([\"---\"] * len(cols)) + \"|\")\n",
    "    for _, row in df.iterrows():\n",
    "        lines.append(\"|\" + \"|\".join(\"\" if pd.isna(v) else str(v) for v in row.tolist()) + \"|\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _render_llm_prompt(ctx: dict) -> str:\n",
    "    return (\n",
    "        \"คุณคือ Data/Quant strategist ภาษาไทย ทำหน้าที่แปลผลลัพธ์เชิงตัวเลขจาก BSDE framework ให้กลายเป็นนโยบายที่ปฏิบัติได้จริง \"\n",
    "        \"ให้ตอบเป็นภาษาไทยแบบ dev/data expert ทับศัพท์และคงชื่อเทคนิค เช่น BSDE, intensity, severity, utility\\n\\n\"\n",
    "        \"## BSDE Framework (Quantitative Engine)\\n\"\n",
    "        \"- Input: Loss Data, Cost Data, Agent Profile\\n\"\n",
    "        \"- Process: backward loop จาก t=T → t=0 เพื่อหา optimal control u(t,X_t)\\n\"\n",
    "        \"- Output: Optimal Control Process u*(t)\\n\\n\"\n",
    "        \"## ผลลัพธ์จาก solver\\n\"\n",
    "        f\"- baseline_E_exp_minus_eta_XT: {ctx['baseline']}\\n\"\n",
    "        f\"- optimal_objective: {ctx['optimal_objective']}\\n\"\n",
    "        f\"- improvement_ratio: {ctx['improvement_ratio']}\\n\"\n",
    "        f\"- horizon_steps: {ctx['steps']}\\n\"\n",
    "        f\"- avg_lambda0_per_dt: {ctx['avg_lambda']}\\n\"\n",
    "        f\"- optimal_controls: u1*={ctx['u1']}, u2*={ctx['u2']}\\n\"\n",
    "        f\"- discount_rate_r: {ctx['r']}, risk_aversion_eta: {ctx['eta']}\\n\"\n",
    "        f\"- budget_total_THB: {ctx['budget']}\\n\\n\"\n",
    "        \"## ตาราง intensity (ย่อ)\\n\"\n",
    "        f\"{ctx['lambda_table']}\\n\\n\"\n",
    "        \"## โจทย์การสรุปผล\\n\"\n",
    "        \"1) Executive summary 5–8 บรรทัด อธิบาย baseline vs optimal และความหมายของ improvement_ratio\\n\"\n",
    "        \"2) เสนอ Static Strategy: ระบุสัดส่วน u1,u2 เป็นตัวเลข 0–1 และบริบทการใช้\\n\"\n",
    "        \"3) เสนอ Dynamic Strategy: if–then rules อิง λ_t และ proxy ของ size พร้อม thresholds\\n\"\n",
    "        \"4) จัดแผน Budget allocation ให้สอดคล้องกับ u1/u2* ภายใต้งบประมาณที่กำหนด พร้อมเหตุผลด้าน expected utility\\n\"\n",
    "        \"5) Roadmap 3 เฟส: Quick win (≤90 วัน), Mid-term (≤12 เดือน), Long-term (>12 เดือน) ผูกกับ control และ data requirement\\n\"\n",
    "        \"6) สรุป Assumptions และข้อจำกัดที่สำคัญ\\n\"\n",
    "        \"ห้ามตอบเป็นโค้ดหรือครอบด้วย code fence\"\n",
    "    )\n",
    "\n",
    "run_bsde_pipeline_and_report(10_000_000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377b9010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSDE mock + dynamic policy (backward recursion) + Gemini reporting\n",
    "# - จำลอง λ0(t) และ severity (lognormal)\n",
    "# - คำนวณ “นโยบายแบบไดนามิก” ด้วย BSDE-style backward recursion (risk-sensitive CE)\n",
    "# - เทียบกับ “นโยบายคงที่” แบบ grid search เบา ๆ\n",
    "# - ใช้ Gemini สร้างรายงานเชิงกลยุทธ์จากผลลัพธ์ (mock)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "OUT_DIR = Path(\"bsde_out_bsde_mock\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    \"timezone\": \"Asia/Bangkok\",\n",
    "    \"dt_hours\": 1,\n",
    "    \"r_annual\": 0.03,             # ไม่ใช้ใน mock BSDE นี้ (โฟกัส cost+loss)\n",
    "    \"eta_per_million\": 0.5,       # risk aversion บนหน่วยล้านบาท\n",
    "    \"scale\": \"Million THB\",\n",
    "    \"budget_total_thb\": 10_000_000.0,\n",
    "\n",
    "    # horizon (mock 7 วัน hourly)\n",
    "    \"horizon_start_utc\": \"2021-04-01T00:00:00Z\",\n",
    "    \"horizon_end_utc\": \"2021-04-07T00:00:00Z\",\n",
    "\n",
    "    # mock λ0(t) และ severity\n",
    "    \"lam0_base_per_hour\": 0.03,\n",
    "    \"lam0_amp\": 0.02,\n",
    "    \"severity_lognormal_mu\": float(np.log(1.2)),\n",
    "    \"severity_lognormal_sigma\": 0.6,  # บนหน่วย \"ล้านบาท\"\n",
    "\n",
    "    # control effectiveness\n",
    "    \"k1\": 1.2,  # u1 ลดความถี่: gamma1(u1)=exp(-k1*u1)\n",
    "    \"k2\": 1.0,  # u2 ลดความรุนแรง: gamma2(u2)=exp(-k2*u2)\n",
    "\n",
    "    # cost ต่อชั่วโมง (หน่วยบาท) → แปลงเป็นล้านบาทภายใน\n",
    "    \"c1_b_thb_per_hour\": 2.0e5,   # quadratic: 0.5*b*u^2\n",
    "    \"c2_b_thb_per_hour\": 1.0e5,\n",
    "\n",
    "    # grid และ sample\n",
    "    \"u_grid_bsde\": 5,             # 0.0..1.0 แบ่ง 5 ค่า (0.0, 0.25, 0.5, 0.75, 1.0)\n",
    "    \"samples_per_step\": 300,      # จำลองต่อสเต็ปเพื่อคำนวณ E[exp(eta*(cost+loss))]\n",
    "    \"u_grid_static\": 5,           # สำหรับ static policy เทียบกัน\n",
    "}\n",
    "\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "API_KEY = \"AIzaSyAndvZufK3ms-pYx8DO7vBGJjaxsfS-Ecs\"\n",
    "\n",
    "# ------------------- HELPERS -------------------\n",
    "def _to_md_table(df: pd.DataFrame) -> str:\n",
    "    if df.empty:\n",
    "        return \"\"\n",
    "    cols = [str(c) for c in df.columns]\n",
    "    lines = []\n",
    "    lines.append(\"|\" + \"|\".join(cols) + \"|\")\n",
    "    lines.append(\"|\" + \"|\".join([\"---\"] * len(cols)) + \"|\")\n",
    "    for _, row in df.iterrows():\n",
    "        lines.append(\"|\" + \"|\".join(\"\" if pd.isna(v) else str(v) for v in row.tolist()) + \"|\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def gamma1(u1: float, k1: float) -> float:\n",
    "    u1 = float(min(max(u1, 0.0), 1.0))\n",
    "    return float(np.exp(-k1 * u1))\n",
    "\n",
    "def gamma2(u2: float, k2: float) -> float:\n",
    "    u2 = float(min(max(u2, 0.0), 1.0))\n",
    "    return float(np.exp(-k2 * u2))\n",
    "\n",
    "def hourly_cost_million(u1: float, u2: float, cfg: dict) -> float:\n",
    "    c1 = 0.5 * cfg[\"c1_b_thb_per_hour\"] * (u1 ** 2)\n",
    "    c2 = 0.5 * cfg[\"c2_b_thb_per_hour\"] * (u2 ** 2)\n",
    "    return (c1 + c2) * 1e-6  # บาท → ล้านบาท\n",
    "\n",
    "def make_horizon_grid(cfg: dict):\n",
    "    start = pd.Timestamp(cfg[\"horizon_start_utc\"])\n",
    "    end = pd.Timestamp(cfg[\"horizon_end_utc\"])\n",
    "    grid = pd.date_range(start, end, freq=f\"{cfg['dt_hours']}h\", tz=\"UTC\")\n",
    "    return grid\n",
    "\n",
    "def mock_lambda_series(grid: pd.DatetimeIndex, cfg: dict) -> np.ndarray:\n",
    "    n = max(len(grid) - 1, 1)\n",
    "    x = np.linspace(0, 4 * np.pi, n)\n",
    "    lam = cfg[\"lam0_base_per_hour\"] + cfg[\"lam0_amp\"] * np.sin(x)\n",
    "    lam = np.clip(lam, 0.001, None)\n",
    "    return lam\n",
    "\n",
    "def severity_sampler_million(n: int, mu: float, sigma: float) -> np.ndarray:\n",
    "    return np.exp(np.random.normal(mu, sigma, size=int(n)))  # หน่วยล้านบาท\n",
    "\n",
    "# ------------------- STATIC POLICY (อ้างอิง) -------------------\n",
    "def static_objective_logU(lam_per_hour: np.ndarray, mu: float, sigma: float, u1: float, u2: float, cfg: dict) -> float:\n",
    "    \"\"\"\n",
    "    คำนวณ log U0 สำหรับนโยบายคงที่: U0 = Π_k E[exp(eta*(cost_k+loss_k(u)))]\n",
    "    (CE แบบ risk-sensitive) แบบรวดเร็วด้วย Monte Carlo ต่อสเต็ป\n",
    "    \"\"\"\n",
    "    eta = cfg[\"eta_per_million\"]\n",
    "    dt_h = cfg[\"dt_hours\"]\n",
    "    g1 = gamma1(u1, cfg[\"k1\"])\n",
    "    g2 = gamma2(u2, cfg[\"k2\"])\n",
    "    cost_h = hourly_cost_million(u1, u2, cfg)\n",
    "\n",
    "    logU = 0.0\n",
    "    for k in range(len(lam_per_hour)):\n",
    "        lam_u = max(0.0, g1 * lam_per_hour[k]) * dt_h\n",
    "        # draw N claims per sample\n",
    "        Ns = np.random.poisson(lam_u, size=cfg[\"samples_per_step\"])\n",
    "        losses = []\n",
    "        for N in Ns:\n",
    "            if N <= 0:\n",
    "                losses.append(0.0)\n",
    "            else:\n",
    "                losses.append(float(np.sum(g2 * severity_sampler_million(N, mu, sigma))))\n",
    "        losses = np.asarray(losses, dtype=float)\n",
    "        y = eta * (cost_h * dt_h + losses)\n",
    "        m = float(np.max(y))\n",
    "        log_eexp = m + np.log(np.mean(np.exp(np.clip(y - m, -1000.0, 0.0))))\n",
    "        logU += float(np.clip(log_eexp, -745.0, 709.0))\n",
    "    return float(logU)\n",
    "\n",
    "def find_static_policy(lam_per_hour: np.ndarray, mu: float, sigma: float, cfg: dict):\n",
    "    grid = np.linspace(0.0, 1.0, cfg[\"u_grid_static\"])\n",
    "    best = {\"u1\": 0.0, \"u2\": 0.0, \"logU0\": float(\"+inf\")}\n",
    "    for u1 in grid:\n",
    "        for u2 in grid:\n",
    "            logU = static_objective_logU(lam_per_hour, mu, sigma, float(u1), float(u2), cfg)\n",
    "            if logU < best[\"logU0\"]:\n",
    "                best = {\"u1\": float(u1), \"u2\": float(u2), \"logU0\": float(logU)}\n",
    "    return best\n",
    "\n",
    "# ------------------- BSDE-STYLE BACKWARD POLICY -------------------\n",
    "def bsde_backward_policy(lam_per_hour: np.ndarray, mu: float, sigma: float, cfg: dict):\n",
    "    \"\"\"\n",
    "    Backward recursion (risk-sensitive):\n",
    "      U_T = 1  → logU_T = 0\n",
    "      เลือก u_k เพื่อลด U_k = E[exp(eta*(cost_k+loss_k(u)))] * U_{k+1}\n",
    "      ⇒ logU_k = min_u { log E[exp(eta*(cost_k+loss_k(u)))] + logU_{k+1} }\n",
    "    คืนค่าลิสต์ u1*, u2* ต่อเวลา และ logU0\n",
    "    \"\"\"\n",
    "    eta = cfg[\"eta_per_million\"]\n",
    "    dt_h = cfg[\"dt_hours\"]\n",
    "    grid_u = np.linspace(0.0, 1.0, cfg[\"u_grid_bsde\"])\n",
    "\n",
    "    T = len(lam_per_hour)\n",
    "    u1_star = np.zeros(T, dtype=float)\n",
    "    u2_star = np.zeros(T, dtype=float)\n",
    "\n",
    "    logU_next = 0.0  # logU_T\n",
    "    # เดินย้อนเวลา\n",
    "    for k in reversed(range(T)):\n",
    "        lam_k = lam_per_hour[k]\n",
    "        best_log = float(\"+inf\")\n",
    "        best_u1, best_u2 = 0.0, 0.0\n",
    "\n",
    "        for u1 in grid_u:\n",
    "            g1 = gamma1(float(u1), cfg[\"k1\"])\n",
    "            lam_u_dt = max(0.0, g1 * lam_k) * dt_h\n",
    "            for u2 in grid_u:\n",
    "                g2 = gamma2(float(u2), cfg[\"k2\"])\n",
    "                cost_h = hourly_cost_million(float(u1), float(u2), cfg)\n",
    "\n",
    "                # MC สำหรับ log E[exp(eta*(cost+loss))]\n",
    "                Ns = np.random.poisson(lam_u_dt, size=cfg[\"samples_per_step\"])\n",
    "                losses = []\n",
    "                for N in Ns:\n",
    "                    if N <= 0:\n",
    "                        losses.append(0.0)\n",
    "                    else:\n",
    "                        losses.append(float(np.sum(g2 * severity_sampler_million(N, mu, sigma))))\n",
    "                losses = np.asarray(losses, dtype=float)\n",
    "                y = eta * (cost_h * dt_h + losses)\n",
    "\n",
    "                m = float(np.max(y))\n",
    "                log_eexp = m + np.log(np.mean(np.exp(np.clip(y - m, -1000.0, 0.0))))\n",
    "                log_eexp = float(np.clip(log_eexp, -745.0, 709.0))\n",
    "\n",
    "                cand = log_eexp + logU_next\n",
    "                if cand < best_log:\n",
    "                    best_log = cand\n",
    "                    best_u1, best_u2 = float(u1), float(u2)\n",
    "\n",
    "        u1_star[k] = best_u1\n",
    "        u2_star[k] = best_u2\n",
    "        logU_next = best_log  # ใช้เป็น logU_{k} สำหรับสเต็ปก่อนหน้า\n",
    "\n",
    "    return {\n",
    "        \"u1_series\": u1_star.tolist(),\n",
    "        \"u2_series\": u2_star.tolist(),\n",
    "        \"logU0\": float(logU_next)\n",
    "    }\n",
    "\n",
    "# ------------------- PIPELINE (MOCK BSDE + REPORT) -------------------\n",
    "def run_bsde_mock_and_report():\n",
    "    grid = make_horizon_grid(CFG)\n",
    "    lam0 = mock_lambda_series(grid, CFG)\n",
    "    mu = CFG[\"severity_lognormal_mu\"]\n",
    "    sigma = CFG[\"severity_lognormal_sigma\"]\n",
    "\n",
    "    # Static (อ้างอิง)\n",
    "    best_static = find_static_policy(lam0, mu, sigma, CFG)\n",
    "    static_obj = float(np.exp(np.clip(best_static[\"logU0\"], -745.0, 709.0)))\n",
    "\n",
    "    # BSDE dynamic policy\n",
    "    dyn = bsde_backward_policy(lam0, mu, sigma, CFG)\n",
    "    dyn_obj = float(np.exp(np.clip(dyn[\"logU0\"], -745.0, 709.0)))\n",
    "\n",
    "    # Compose policy object (mock-friendly แต่มีผลลัพธ์จากตัวแกน)\n",
    "    policy = {\n",
    "        \"config\": {\n",
    "            \"timezone\": CFG[\"timezone\"],\n",
    "            \"dt_hours\": CFG[\"dt_hours\"],\n",
    "            \"r_annual\": CFG[\"r_annual\"],\n",
    "            \"eta_per_million\": CFG[\"eta_per_million\"],\n",
    "            \"k1\": CFG[\"k1\"], \"k2\": CFG[\"k2\"],\n",
    "            \"scale\": CFG[\"scale\"]\n",
    "        },\n",
    "        \"time_grid_start\": grid[0].isoformat(),\n",
    "        \"time_grid_end\": grid[-1].isoformat(),\n",
    "        \"steps\": int(len(lam0)),\n",
    "        \"lambda0_avg_per_hour\": float(np.mean(lam0)),\n",
    "        \"severity_lognormal\": {\"mu\": mu, \"sigma\": sigma, \"unit\": \"Million THB\"},\n",
    "        # อ้างอิง baseline = policy คงที่ที่ u1=u2=0\n",
    "        \"baseline_E_exp_eta_cost\": float(np.exp(static_objective_logU(lam0, mu, sigma, 0.0, 0.0, CFG))),\n",
    "        \"static_optimal\": {\"u1\": best_static[\"u1\"], \"u2\": best_static[\"u2\"], \"objective\": static_obj},\n",
    "        \"bsde_dynamic\": {\n",
    "            \"objective\": dyn_obj,\n",
    "            \"u1_series\": dyn[\"u1_series\"],\n",
    "            \"u2_series\": dyn[\"u2_series\"]\n",
    "        },\n",
    "        \"improvement_ratio_static_vs_dyn\": (static_obj / dyn_obj) if dyn_obj > 0 else None\n",
    "    }\n",
    "\n",
    "    # Preview λ0 (24 ชั่วโมงแรก)\n",
    "    preview = pd.DataFrame({\n",
    "        \"t_bin_start_utc\": grid[:-1][:24],\n",
    "        \"lambda0_per_hour\": lam0[:24]\n",
    "    })\n",
    "    md_table = _to_md_table(preview)\n",
    "\n",
    "    # Budget mock\n",
    "    interventions = {\n",
    "        \"candidates\": [\n",
    "            {\"id\": \"U12.1\", \"name\": \"ทีม GTG 24ชม.\", \"map\": \"u1\"},\n",
    "            {\"id\": \"U17.1\", \"name\": \"ซ่อมบำรุง Sub station\", \"map\": \"u2\"},\n",
    "            {\"id\": \"RESERVE\", \"name\": \"งบสำรอง\", \"map\": \"reserve\"}\n",
    "        ],\n",
    "        \"target_allocation\": {\n",
    "            \"total_budget_thb\": CFG[\"budget_total_thb\"],\n",
    "            \"U12.1_thb\": 5_000_000.0,\n",
    "            \"U17.1_thb\": 3_000_000.0,\n",
    "            \"RESERVE_thb\": 2_000_000.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Persist JSONs\n",
    "    (OUT_DIR / \"policy_bsde.json\").write_text(json.dumps(policy, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    (OUT_DIR / \"interventions.json\").write_text(json.dumps(interventions, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # ------------------- Gemini Reporting -------------------\n",
    "    prompt = (\n",
    "        \"คุณคือ Data/Quant strategist ภาษาไทย ทำหน้าที่แปลผลลัพธ์จาก BSDE-style dynamic policy ให้เป็นนโยบายที่ปฏิบัติได้จริง \"\n",
    "        \"ตอบแบบ dev/data expert ทับศัพท์เทคนิค เช่น BSDE, intensity, severity, utility โดยมีตัวเลขอ้างอิงชัดเจน\\n\\n\"\n",
    "        \"## โมเดล/ฮอไรซอน (Mock)\\n\"\n",
    "        f\"- Horizon: {policy['time_grid_start']} → {policy['time_grid_end']} | steps={policy['steps']}\\n\"\n",
    "        f\"- avg λ₀/ชั่วโมง: {policy['lambda0_avg_per_hour']:.4f}\\n\"\n",
    "        f\"- Severity lognormal(mu={mu:.4f}, sigma={sigma:.2f}, unit={CFG['scale']})\\n\"\n",
    "        f\"- eta(per {CFG['scale']}): {CFG['eta_per_million']}\\n\\n\"\n",
    "        \"## วัตถุประสงค์ (risk-sensitive, CE of cost)\\n\"\n",
    "        f\"- baseline (u1=0,u2=0): {policy['baseline_E_exp_eta_cost']:.4f}\\n\"\n",
    "        f\"- static optimal: u1={policy['static_optimal']['u1']:.2f}, u2={policy['static_optimal']['u2']:.2f}, \"\n",
    "        f\"objective={policy['static_optimal']['objective']:.4f}\\n\"\n",
    "        f\"- BSDE dynamic: objective={policy['bsde_dynamic']['objective']:.4f}, \"\n",
    "        \"ได้ลำดับ u1*(t), u2*(t) ตามเวลา\\n\"\n",
    "        f\"- improvement(static→dynamic): {policy['improvement_ratio_static_vs_dyn']:.4f}\\n\\n\"\n",
    "        \"## λ_t (ย่อ – 24 ชม.แรก)\\n\"\n",
    "        f\"{md_table}\\n\\n\"\n",
    "        \"## โจทย์เพื่อสรุปกลยุทธ์\\n\"\n",
    "        \"- เปรียบเทียบ Static vs Dynamic ว่าควรใช้เมื่อไร พร้อม if–then rule บน threshold ของ λ_t\\n\"\n",
    "        \"- ผูกงบประมาณ 10 ล้านบาท/ปีเข้ากับ u1 (ลดความถี่) และ u2 (ลดความรุนแรง)\\n\"\n",
    "        \"- สรุป Budget Allocation ตามตัวอย่าง: \"\n",
    "        f\"U12.1 {interventions['target_allocation']['U12.1_thb']:.0f} บาท, \"\n",
    "        f\"U17.1 {interventions['target_allocation']['U17.1_thb']:.0f} บาท, \"\n",
    "        f\"สำรอง {interventions['target_allocation']['RESERVE_thb']:.0f} บาท\\n\"\n",
    "        \"- ใส่เหตุผลเชิงปริมาณ: แม้บาง risk severity สูง แต่เหตุการณ์ GTG Trip เกิดถี่กว่า → expected loss สูงกว่า → u1 priority\\n\"\n",
    "        \"- ห้ามส่งโค้ด/ห้าม code fence\"\n",
    "    )\n",
    "\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    resp = client.models.generate_content(model=MODEL, contents=prompt)\n",
    "    text = getattr(resp, \"text\", str(resp)).strip()\n",
    "    (OUT_DIR / \"final_output_bsde.md\").write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "# เรียก pipeline (ไม่ต้องใช้ if __main__)\n",
    "run_bsde_mock_and_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
